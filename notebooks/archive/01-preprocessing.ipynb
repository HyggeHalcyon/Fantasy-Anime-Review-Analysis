{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6cfd9b3b",
   "metadata": {},
   "source": [
    "### Depedencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "6889958b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import contractions\n",
    "import spacy\n",
    "import string\n",
    "from collections import Counter\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from spellchecker import SpellChecker\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "nltk.download('wordnet', quiet=True)\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f9a9622",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "- Tokenizing\n",
    "- Lowercasing\n",
    "- Stop Word Removal\n",
    "- Frequent Words Removal\n",
    "- Rare Words Removal\n",
    "- Stemming\n",
    "- Lemmatization\n",
    "- Chat Words Conversion\n",
    "- Spelling Corrections\n",
    "\n",
    "References: \n",
    "- [Getting started with Text Preprocessing](https://www.kaggle.com/code/sudalairajkumar/getting-started-with-text-preprocessing)\n",
    "- [NLP - Data Preprocessing and Cleaning](https://www.kaggle.com/code/colearninglounge/nlp-data-preprocessing-and-cleaning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "877d1b63",
   "metadata": {},
   "source": [
    "### Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "7acf928b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>anime_title</th>\n",
       "      <th>review_url</th>\n",
       "      <th>date</th>\n",
       "      <th>username</th>\n",
       "      <th>user_review_count</th>\n",
       "      <th>is_preliminary</th>\n",
       "      <th>episodes_watched</th>\n",
       "      <th>recommendation</th>\n",
       "      <th>rating</th>\n",
       "      <th>review</th>\n",
       "      <th>total_reactions</th>\n",
       "      <th>nice_count</th>\n",
       "      <th>love_it_count</th>\n",
       "      <th>funny_count</th>\n",
       "      <th>confusing_count</th>\n",
       "      <th>informative_count</th>\n",
       "      <th>well_written_count</th>\n",
       "      <th>creative_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>503754</td>\n",
       "      <td>Sousou no Frieren</td>\n",
       "      <td>https://myanimelist.net/reviews.php?id=503754</td>\n",
       "      <td>Oct 13, 2023 8:38 AM</td>\n",
       "      <td>Czekaj</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>5/28</td>\n",
       "      <td>Recommended</td>\n",
       "      <td>10</td>\n",
       "      <td>With lives so short, why do we even bother? To...</td>\n",
       "      <td>1341</td>\n",
       "      <td>280</td>\n",
       "      <td>829</td>\n",
       "      <td>43</td>\n",
       "      <td>58</td>\n",
       "      <td>5</td>\n",
       "      <td>124</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>519189</td>\n",
       "      <td>Sousou no Frieren</td>\n",
       "      <td>https://myanimelist.net/reviews.php?id=519189</td>\n",
       "      <td>Mar 22, 2024 12:40 PM</td>\n",
       "      <td>chekkit</td>\n",
       "      <td>25</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Recommended</td>\n",
       "      <td>10</td>\n",
       "      <td>I feel so catered to.\\n\\r\\nIt feels like an et...</td>\n",
       "      <td>1188</td>\n",
       "      <td>243</td>\n",
       "      <td>774</td>\n",
       "      <td>43</td>\n",
       "      <td>47</td>\n",
       "      <td>8</td>\n",
       "      <td>70</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>519472</td>\n",
       "      <td>Sousou no Frieren</td>\n",
       "      <td>https://myanimelist.net/reviews.php?id=519472</td>\n",
       "      <td>Mar 24, 2024 2:03 AM</td>\n",
       "      <td>Trikkiez</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Not Recommended</td>\n",
       "      <td>4</td>\n",
       "      <td>Style-\\r\\nFrieren doesn't have its own unique ...</td>\n",
       "      <td>4111</td>\n",
       "      <td>612</td>\n",
       "      <td>100</td>\n",
       "      <td>1926</td>\n",
       "      <td>1318</td>\n",
       "      <td>28</td>\n",
       "      <td>116</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>512466</td>\n",
       "      <td>Sousou no Frieren</td>\n",
       "      <td>https://myanimelist.net/reviews.php?id=512466</td>\n",
       "      <td>Jan 12, 2024 11:25 AM</td>\n",
       "      <td>ShabbaRico</td>\n",
       "      <td>12</td>\n",
       "      <td>True</td>\n",
       "      <td>18/28</td>\n",
       "      <td>Not Recommended</td>\n",
       "      <td>5</td>\n",
       "      <td>TL;DR: 5/10, I don't recommend this for anyone...</td>\n",
       "      <td>915</td>\n",
       "      <td>180</td>\n",
       "      <td>27</td>\n",
       "      <td>395</td>\n",
       "      <td>261</td>\n",
       "      <td>9</td>\n",
       "      <td>41</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>503760</td>\n",
       "      <td>Sousou no Frieren</td>\n",
       "      <td>https://myanimelist.net/reviews.php?id=503760</td>\n",
       "      <td>Oct 13, 2023 9:10 AM</td>\n",
       "      <td>TheRealist68</td>\n",
       "      <td>16</td>\n",
       "      <td>True</td>\n",
       "      <td>6/28</td>\n",
       "      <td>Mixed Feelings</td>\n",
       "      <td>9</td>\n",
       "      <td>Through 3 episodes, Frieren appears to be a un...</td>\n",
       "      <td>949</td>\n",
       "      <td>410</td>\n",
       "      <td>60</td>\n",
       "      <td>31</td>\n",
       "      <td>312</td>\n",
       "      <td>10</td>\n",
       "      <td>122</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   review_id        anime_title  \\\n",
       "0     503754  Sousou no Frieren   \n",
       "1     519189  Sousou no Frieren   \n",
       "2     519472  Sousou no Frieren   \n",
       "3     512466  Sousou no Frieren   \n",
       "4     503760  Sousou no Frieren   \n",
       "\n",
       "                                      review_url                   date  \\\n",
       "0  https://myanimelist.net/reviews.php?id=503754   Oct 13, 2023 8:38 AM   \n",
       "1  https://myanimelist.net/reviews.php?id=519189  Mar 22, 2024 12:40 PM   \n",
       "2  https://myanimelist.net/reviews.php?id=519472   Mar 24, 2024 2:03 AM   \n",
       "3  https://myanimelist.net/reviews.php?id=512466  Jan 12, 2024 11:25 AM   \n",
       "4  https://myanimelist.net/reviews.php?id=503760   Oct 13, 2023 9:10 AM   \n",
       "\n",
       "       username  user_review_count  is_preliminary episodes_watched  \\\n",
       "0        Czekaj                  5            True             5/28   \n",
       "1       chekkit                 25           False              NaN   \n",
       "2      Trikkiez                  3           False              NaN   \n",
       "3    ShabbaRico                 12            True            18/28   \n",
       "4  TheRealist68                 16            True             6/28   \n",
       "\n",
       "    recommendation  rating                                             review  \\\n",
       "0      Recommended      10  With lives so short, why do we even bother? To...   \n",
       "1      Recommended      10  I feel so catered to.\\n\\r\\nIt feels like an et...   \n",
       "2  Not Recommended       4  Style-\\r\\nFrieren doesn't have its own unique ...   \n",
       "3  Not Recommended       5  TL;DR: 5/10, I don't recommend this for anyone...   \n",
       "4   Mixed Feelings       9  Through 3 episodes, Frieren appears to be a un...   \n",
       "\n",
       "   total_reactions  nice_count  love_it_count  funny_count  confusing_count  \\\n",
       "0             1341         280            829           43               58   \n",
       "1             1188         243            774           43               47   \n",
       "2             4111         612            100         1926             1318   \n",
       "3              915         180             27          395              261   \n",
       "4              949         410             60           31              312   \n",
       "\n",
       "   informative_count  well_written_count  creative_count  \n",
       "0                  5                 124               2  \n",
       "1                  8                  70               3  \n",
       "2                 28                 116              11  \n",
       "3                  9                  41               2  \n",
       "4                 10                 122               4  "
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complete_df = pd.read_csv(r\"../../data/raw/top_150_fantasy_reviews.csv\")\n",
    "df = complete_df[[\"review\"]]\n",
    "df[\"review\"] = df[\"review\"].astype(str)\n",
    "complete_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aeaa4f9",
   "metadata": {},
   "source": [
    "### Lowercasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "e82c656e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>with lives so short, why do we even bother? to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i feel so catered to.\\n\\r\\nit feels like an et...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>style-\\r\\nfrieren doesn't have its own unique ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tl;dr: 5/10, i don't recommend this for anyone...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>through 3 episodes, frieren appears to be a un...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review\n",
       "0  with lives so short, why do we even bother? to...\n",
       "1  i feel so catered to.\\n\\r\\nit feels like an et...\n",
       "2  style-\\r\\nfrieren doesn't have its own unique ...\n",
       "3  tl;dr: 5/10, i don't recommend this for anyone...\n",
       "4  through 3 episodes, frieren appears to be a un..."
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"review\"] = df[\"review\"].str.lower()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73dc4ed2",
   "metadata": {},
   "source": [
    "### URLs and Emails Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "38b58d16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>with lives so short, why do we even bother? to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i feel so catered to.\\n\\r\\nit feels like an et...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>style-\\r\\nfrieren doesn't have its own unique ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tl;dr: 5/10, i don't recommend this for anyone...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>through 3 episodes, frieren appears to be a un...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review\n",
       "0  with lives so short, why do we even bother? to...\n",
       "1  i feel so catered to.\\n\\r\\nit feels like an et...\n",
       "2  style-\\r\\nfrieren doesn't have its own unique ...\n",
       "3  tl;dr: 5/10, i don't recommend this for anyone...\n",
       "4  through 3 episodes, frieren appears to be a un..."
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_urls(text):\n",
    "    pattern = re.compile(r'http\\S+|www\\S+|\\S+@\\S+')\n",
    "    return pattern.sub(r'', text)\n",
    "df[\"review\"] = df[\"review\"].apply(remove_urls)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f9135b",
   "metadata": {},
   "source": [
    "### Mentions Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "e6501b55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>with lives so short, why do we even bother? to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i feel so catered to.\\n\\r\\nit feels like an et...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>style-\\r\\nfrieren doesn't have its own unique ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tl;dr: 5/10, i don't recommend this for anyone...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>through 3 episodes, frieren appears to be a un...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review\n",
       "0  with lives so short, why do we even bother? to...\n",
       "1  i feel so catered to.\\n\\r\\nit feels like an et...\n",
       "2  style-\\r\\nfrieren doesn't have its own unique ...\n",
       "3  tl;dr: 5/10, i don't recommend this for anyone...\n",
       "4  through 3 episodes, frieren appears to be a un..."
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_mentions(text):\n",
    "    pattern = re.compile(r'@\\w+')\n",
    "    return pattern.sub(r'', text)\n",
    "df[\"review\"] = df[\"review\"].apply(remove_mentions)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eefeaf6c",
   "metadata": {},
   "source": [
    "### Non-Alphanumeric Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "3489629e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>with lives so short why do we even bother to s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i feel so catered to\\n\\r\\nit feels like an ete...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>style\\r\\nfrieren doesn't have its own unique s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tldr 510 i don't recommend this for anyone tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>through 3 episodes frieren appears to be a uni...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review\n",
       "0  with lives so short why do we even bother to s...\n",
       "1  i feel so catered to\\n\\r\\nit feels like an ete...\n",
       "2  style\\r\\nfrieren doesn't have its own unique s...\n",
       "3  tldr 510 i don't recommend this for anyone tha...\n",
       "4  through 3 episodes frieren appears to be a uni..."
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PUNCT_TO_REMOVE = string.punctuation.replace(\"'\", \"\")  # remove apostrophes from punctuation\n",
    "def remove_non_alphanumeric(text):\n",
    "    pattern = re.compile(r\"[^a-z'\\s]\")\n",
    "    return pattern.sub(r'', text)\n",
    "\n",
    "df['review'] = df['review'].apply(lambda text: remove_punctuation(text))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a992cf",
   "metadata": {},
   "source": [
    "### Chat Word Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "6af7570c",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_words_str = \"\"\"\n",
    "AFAIK=As Far As I Know\n",
    "AFK=Away From Keyboard\n",
    "ASAP=As Soon As Possible\n",
    "ATK=At The Keyboard\n",
    "ATM=At The Moment\n",
    "A3=Anytime, Anywhere, Anyplace\n",
    "BAK=Back At Keyboard\n",
    "BBL=Be Back Later\n",
    "BBS=Be Back Soon\n",
    "BFN=Bye For Now\n",
    "B4N=Bye For Now\n",
    "BRB=Be Right Back\n",
    "BRT=Be Right There\n",
    "BTW=By The Way\n",
    "B4=Before\n",
    "B4N=Bye For Now\n",
    "CU=See You\n",
    "CUL8R=See You Later\n",
    "CYA=See You\n",
    "FAQ=Frequently Asked Questions\n",
    "FC=Fingers Crossed\n",
    "FWIW=For What It's Worth\n",
    "FYI=For Your Information\n",
    "GAL=Get A Life\n",
    "GG=Good Game\n",
    "GN=Good Night\n",
    "GMTA=Great Minds Think Alike\n",
    "GR8=Great!\n",
    "G9=Genius\n",
    "IC=I See\n",
    "ICQ=I Seek you (also a chat program)\n",
    "ILU=ILU: I Love You\n",
    "IMHO=In My Honest/Humble Opinion\n",
    "IMO=In My Opinion\n",
    "IOW=In Other Words\n",
    "IRL=In Real Life\n",
    "KISS=Keep It Simple, Stupid\n",
    "LDR=Long Distance Relationship\n",
    "LMAO=Laugh My A.. Off\n",
    "LOL=Laughing Out Loud\n",
    "LTNS=Long Time No See\n",
    "L8R=Later\n",
    "MTE=My Thoughts Exactly\n",
    "M8=Mate\n",
    "NRN=No Reply Necessary\n",
    "OIC=Oh I See\n",
    "PITA=Pain In The A..\n",
    "PRT=Party\n",
    "PRW=Parents Are Watching\n",
    "ROFL=Rolling On The Floor Laughing\n",
    "ROFLOL=Rolling On The Floor Laughing Out Loud\n",
    "ROTFLMAO=Rolling On The Floor Laughing My A.. Off\n",
    "SK8=Skate\n",
    "STATS=Your sex and age\n",
    "ASL=Age, Sex, Location\n",
    "THX=Thank You\n",
    "TTFN=Ta-Ta For Now!\n",
    "TTYL=Talk To You Later\n",
    "U=You\n",
    "U2=You Too\n",
    "U4E=Yours For Ever\n",
    "WB=Welcome Back\n",
    "WTF=What The F...\n",
    "WTG=Way To Go!\n",
    "WUF=Where Are You From?\n",
    "W8=Wait...\n",
    "7K=Sick:-D Laugher\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "2b40994b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>with lives so short why do we even bother to s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i feel so catered to it feels like an eternity...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>style frieren doesn't have its own unique styl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tldr 510 i don't recommend this for anyone tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>through 3 episodes frieren appears to be a uni...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review\n",
       "0  with lives so short why do we even bother to s...\n",
       "1  i feel so catered to it feels like an eternity...\n",
       "2  style frieren doesn't have its own unique styl...\n",
       "3  tldr 510 i don't recommend this for anyone tha...\n",
       "4  through 3 episodes frieren appears to be a uni..."
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_words_map_dict = {}\n",
    "chat_words_list = []\n",
    "\n",
    "for line in chat_words_str.split(\"\\n\"):\n",
    "    if line != \"\":\n",
    "        cw = line.split(\"=\")[0]\n",
    "        cw_expanded = line.split(\"=\")[1]\n",
    "        chat_words_list.append(cw)\n",
    "        chat_words_map_dict[cw] = cw_expanded\n",
    "chat_words_list = set(chat_words_list)\n",
    "\n",
    "def chat_words_conversion(text):\n",
    "    new_text = []\n",
    "    for w in text.split():\n",
    "        if w.upper() in chat_words_list:\n",
    "            new_text.append(chat_words_map_dict[w.upper()])\n",
    "        else:\n",
    "            new_text.append(w)\n",
    "    return \" \".join(new_text)\n",
    "\n",
    "df['review'] = df['review'].apply(lambda text: chat_words_conversion(text))\n",
    "df[\"review\"] = df[\"review\"].str.lower()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f483e8",
   "metadata": {},
   "source": [
    "### Expand Contractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "c9a02e9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>with lives so short why do we even bother to s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i feel so catered to it feels like an eternity...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>style frieren does not have its own unique sty...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tldr 510 i do not recommend this for anyone th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>through 3 episodes frieren appears to be a uni...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review\n",
       "0  with lives so short why do we even bother to s...\n",
       "1  i feel so catered to it feels like an eternity...\n",
       "2  style frieren does not have its own unique sty...\n",
       "3  tldr 510 i do not recommend this for anyone th...\n",
       "4  through 3 episodes frieren appears to be a uni..."
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['review'] = df['review'].apply(lambda text: contractions.fix(text))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ad2882",
   "metadata": {},
   "source": [
    "### Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "9d6f1450",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>life short even bother someone live thousand y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>feel catered feel like eternity since give phe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>style frieren not_have unique style way feel l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tldr not_recommend anyone standard enjoy fanta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>episode frieren appear unique masterpiece stor...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review\n",
       "0  life short even bother someone live thousand y...\n",
       "1  feel catered feel like eternity since give phe...\n",
       "2  style frieren not_have unique style way feel l...\n",
       "3  tldr not_recommend anyone standard enjoy fanta...\n",
       "4  episode frieren appear unique masterpiece stor..."
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words = set(stopwords.words(\"english\"))\n",
    "negation_words = {\"no\", \"not\", \"nor\", \"never\", \"n't\", \"dont\"}\n",
    "stop_words = stop_words - negation_words\n",
    "post_lemmatization_corrections = {\n",
    "    \"datum\": \"data\",\n",
    "    \"cannot\": \"can_not\",\n",
    "    \"dont\": \"do_not\",\n",
    "    \"doesnt\": \"does_not\",\n",
    "    \"wont\": \"will_not\",\n",
    "    \"cant\": \"can_not\",\n",
    "    \"isnt\": \"is_not\",\n",
    "    \"wasnt\": \"was_not\",\n",
    "    \"arent\": \"are_not\"\n",
    "}\n",
    "\n",
    "def lemmatize_words(text):\n",
    "    if not isinstance(text, str) or text.strip() == \"\":\n",
    "        return \"\"\n",
    "\n",
    "    doc = nlp(text)\n",
    "    tokens = []\n",
    "    skip_next = False\n",
    "\n",
    "    for i, token in enumerate(doc):\n",
    "        if skip_next:\n",
    "            skip_next = False\n",
    "            continue\n",
    "\n",
    "        lemma = token.lemma_.lower()\n",
    "        lemma = post_lemmatization_corrections.get(lemma, lemma)\n",
    "\n",
    "        # Preserve negation + meaningful word (negation tagging)\n",
    "        if lemma in negation_words and i + 1 < len(doc):\n",
    "            next_token = doc[i + 1]\n",
    "            if next_token.pos_ in {\"ADJ\", \"VERB\", \"ADV\", \"NOUN\"}:\n",
    "                next_lemma = next_token.lemma_.lower()\n",
    "                next_lemma = post_lemmatization_corrections.get(next_lemma, next_lemma)\n",
    "                tokens.append(f\"{lemma}_{next_lemma}\")\n",
    "                skip_next = True\n",
    "                continue\n",
    "            else:\n",
    "                tokens.append(lemma)\n",
    "        elif lemma not in stop_words and token.is_alpha and len(lemma) > 1:\n",
    "            tokens.append(lemma)\n",
    "\n",
    "    return \" \".join(tokens)\n",
    "    \n",
    "df[\"review\"] = df[\"review\"].apply(lambda text: lemmatize_words(text))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6131fd1",
   "metadata": {},
   "source": [
    "### Saving Cleaned Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2034465",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = df[['review']].rename(columns={'review': 'processed_review'})\n",
    "final_df.to_csv(r\"..\\data\\processed\\reviews_cleaned.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c8260a",
   "metadata": {},
   "source": [
    "# Unused Preprocessing Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a00fdc",
   "metadata": {},
   "source": [
    "### Frequent Words Removal\n",
    "Note: \n",
    "- If we use something like tfidf, this is automatically taken care of.\n",
    "- Shown the process below however, not taken into account for steps to clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "0e7b8594",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('character', 23326),\n",
       " ('one', 14208),\n",
       " ('anime', 14110),\n",
       " ('show', 13788),\n",
       " ('like', 13200),\n",
       " ('story', 13164),\n",
       " ('make', 11710),\n",
       " ('well', 10016),\n",
       " ('good', 9990),\n",
       " ('series', 9690)]"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt = Counter()\n",
    "for review in df[\"review\"]:\n",
    "    for word in review.split():\n",
    "        cnt[word] += 1\n",
    "cnt.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "eae5f59e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>life short even bother someone live thousand y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>feel catered feel eternity since give phenomen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>style frieren not_have unique style way feel e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tldr not_recommend anyone standard enjoy fanta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>episode frieren appear unique masterpiece stor...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review\n",
       "0  life short even bother someone live thousand y...\n",
       "1  feel catered feel eternity since give phenomen...\n",
       "2  style frieren not_have unique style way feel e...\n",
       "3  tldr not_recommend anyone standard enjoy fanta...\n",
       "4  episode frieren appear unique masterpiece stor..."
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FREQWORDS = set([w for (w, wc) in cnt.most_common(10)])\n",
    "def remove_freqwords(text):\n",
    "    \"\"\"custom function to remove the frequent words\"\"\"\n",
    "    return \" \".join([word for word in str(text).split() if word not in FREQWORDS])\n",
    "\n",
    "df[\"review\"] = df[\"review\"].apply(lambda text: remove_freqwords(text))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad1414d",
   "metadata": {},
   "source": [
    "### Rare Words Removal\n",
    "Note:\n",
    "- Shown the process below however, not taken into account for steps to clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "98ad509a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('not_jack', 2),\n",
       " ('reaccure', 2),\n",
       " ('not_episodic', 2),\n",
       " ('summaryoverall', 2),\n",
       " ('easternesque', 2),\n",
       " ('backstorydevelopment', 2),\n",
       " ('saveprotect', 2),\n",
       " ('notre', 2),\n",
       " ('shirō', 2),\n",
       " ('not_in', 2)]"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_rare_words = 10\n",
    "cnt.most_common()[:-n_rare_words-1:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "65d3073c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>life short even bother someone live thousand y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>feel catered feel eternity since give phenomen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>style frieren not_have unique style way feel e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tldr not_recommend anyone standard enjoy fanta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>episode frieren appear unique masterpiece stor...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review\n",
       "0  life short even bother someone live thousand y...\n",
       "1  feel catered feel eternity since give phenomen...\n",
       "2  style frieren not_have unique style way feel e...\n",
       "3  tldr not_recommend anyone standard enjoy fanta...\n",
       "4  episode frieren appear unique masterpiece stor..."
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RAREWORDS = set([w for (w, wc) in cnt.most_common()[:-n_rare_words-1:-1]])\n",
    "def remove_rarewords(text):\n",
    "    \"\"\"custom function to remove the rare words\"\"\"\n",
    "    return \" \".join([word for word in str(text).split() if word not in RAREWORDS])\n",
    "\n",
    "df[\"review\"] = df[\"review\"].apply(lambda text: remove_rarewords(text))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da7e4e77",
   "metadata": {},
   "source": [
    "### Stemming\n",
    "Note:\n",
    "- Shown the process below however, not taken into account for steps to clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "d5312ff1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>life short even bother someon live thousand ye...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>feel cater feel etern sinc give phenomen think...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>style frieren not_hav uniqu style way feel eve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tldr not_recommend anyon standard enjoy fantas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>episod frieren appear uniqu masterpiec storyte...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review\n",
       "0  life short even bother someon live thousand ye...\n",
       "1  feel cater feel etern sinc give phenomen think...\n",
       "2  style frieren not_hav uniqu style way feel eve...\n",
       "3  tldr not_recommend anyon standard enjoy fantas...\n",
       "4  episod frieren appear uniqu masterpiec storyte..."
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer = PorterStemmer()\n",
    "def stem_words(text):\n",
    "    return \" \".join([stemmer.stem(word) for word in text.split()])\n",
    "\n",
    "df[\"review\"] = df[\"review\"].apply(lambda text: stem_words(text))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f493a5e",
   "metadata": {},
   "source": [
    "Some words such as `this` became `thi` and `why` became `whi` which is not intended. To get around this, Lemmatization are used in such cases"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
